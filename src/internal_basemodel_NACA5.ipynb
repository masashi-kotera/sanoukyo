{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "df_NACA5 = pd.read_csv(\"data/df_NACA5.csv\")\n",
    "df_NACA5.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df = df.sample(frac = 1, random_state = 0)\n",
    "    train  = df.head(0)\n",
    "    test = df.head(0)\n",
    "    for ID in set(df['Airfoil_ID']):\n",
    "        df_tmp = df[df['Airfoil_ID']==ID]\n",
    "        N = int(len(df_tmp)*0.9)\n",
    "        train = pd.concat([train,df_tmp.iloc[:N]])\n",
    "        test = pd.concat([test,df_tmp.iloc[N:]])\n",
    "    train_df = train.reset_index(drop=True)\n",
    "    test_df = test.reset_index(drop=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_data(df_NACA5)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5adce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df, use_cols, target):\n",
    "    exp = setup(\n",
    "        data = df[use_cols + [target]],\n",
    "        target = target,\n",
    "        numeric_features = use_cols,\n",
    "        session_id = 42,\n",
    "        normalize = True, \n",
    "        transformation = False,   \n",
    "        verbose = False\n",
    "        )\n",
    "    compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3acd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_df, test_df, use_cols, target, model_name):\n",
    "    exp = setup(\n",
    "        data=train_df[use_cols + [target]],\n",
    "        target=target,\n",
    "        numeric_features=use_cols,\n",
    "        session_id=42,\n",
    "        normalize=True, \n",
    "        transformation=False,   \n",
    "        verbose=False\n",
    "        )\n",
    "    model = create_model(model_name)\n",
    "    plot_model(model, plot='error')\n",
    "    final_model = finalize_model(model)\n",
    "    plot_model(model, plot='feature')\n",
    "    result = predict_model(final_model, data = test_df[use_cols])\n",
    "    return result[\"prediction_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8809487",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Drag'\n",
    "use_cols = ['L', 'P', 'Q', 'XX', 'Re', 'AOA']\n",
    "compare(df_NACA5, use_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba6df6-e6eb-411c-8ca0-d6fb4ef7f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'et'\n",
    "y_pred = predict(train_df, test_df, use_cols, target, model_name)\n",
    "y_true = test_df[target]\n",
    "print(\"MAE =\", mean_absolute_error(y_true, y_pred))\n",
    "print(\"R2  =\", r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Lift'\n",
    "compare(df_NACA5, use_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68365446-3c61-4021-a991-6ce07f353fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'et'\n",
    "y_pred = predict(train_df, test_df, use_cols, target, model_name)\n",
    "y_true = test_df[target]\n",
    "print(\"MAE =\", mean_absolute_error(y_true, y_pred))\n",
    "print(\"R2  =\", r2_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
